import pandas as pd
import numpy as np

from create_player_dict import get_bbref

from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture

from kmodes import kmodes

import seaborn as sns

n_clusters = 13

km = KMeans(n_clusters=n_clusters,n_init=50,max_iter=1000,algorithm='full',random_state=23)
db = DBSCAN()


pca = PCA(n_components=2,svd_solver='auto')
# In [3]: run k_means.py
# Out [3]:
# 2016: 0.358362946988
# 2015: 0.29260287844

# In [12]: list(stats2016[stats2016['labels'] == 10].index)
# Out[13]: ['DeAndre Jordan', 'Dwight Howard', 'Rudy Gobert']

new_feature_space = stats_list = ['2P','2PA','3P','3PA','FT','FTA','ORB', 'DRB','AST','STL','BLK','AST%','STL%','BLK%','USG%','WS/48','dist','tchs', 'pass','dfgm','dfga']

stats = pd.read_csv('../data/all_stats_final.csv')

# pop team column out for purposes of scaling/analysis, and later reattachment
tm = stats.pop('Tm_x')

# set data using stats_list
X = stats[new_feature_space]

# one column (3Par) has a few nans - it makes sense to simply convert these to 0's
X.fillna(value=0,inplace=True)


# normalize data
scaled = normalize(X)



# perform dimension reduction
reduced = pca.fit_transform(scaled)

# fit the model to reduced, scaled 2016 data
# km.fit(scaled)
gm = GaussianMixture(n_components=14,n_init=10)
gm.fit(reduced)

stats['label'] = gm.predict(reduced)
print silhouette_score(scaled,gm.predict(reduced))

# reattach tm column, attach labels
# stats['Tm'] = tm
# stats['label'] = db.labels_
# X['label'] = db.labels_

# # calculate means for each stat for each cluster
# def get_cluster_means(year):
#     stats = df_dict[year]
#     cluster_nums = {}
#     for label in range(0,13):
#         cluster = stats[stats['labels'] == label]
#         cluster.drop('labels',axis=1,inplace=True)
#         means_dict = cluster.describe().loc['mean'].to_dict()
#         means_dict = {k:round(v,4) for k,v in means_dict.items()}
#         cluster_nums[label] = means_dict
#     return cluster_nums
#
# def view_means_for_stat(stat,stats_dict):
#     '''
#     Choose stat string from stats_list (line 22)!
#     For second arg, pass in dictionary generated by get_cluster_means
#     '''
#     stat_dict = {}
#     for cluster in range(0,n_clusters):
#         stat_dict[cluster] = stats_dict[cluster][stat]
#     return stat_dict
#
# cluster_stats_2015 = get_cluster_means(2015)
# cluster_stats_2016 = get_cluster_means(2016)
# #
new_feature_space.append('label')
# print "Silhouette Score: {}".format(silhouette_score(scaled,km.labels_))
clustered_feature_space = stats.set_index('player_year')[new_feature_space]
clustered_feature_space.to_csv('../data/clustered_feature_space.csv')
# stats.to_csv('../data/clustered_stats.csv')
